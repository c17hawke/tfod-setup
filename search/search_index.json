{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Configuration steps for TensorFlow object detection- STEP-1 Download the following content- Download v1.13.0 model. Download the ssd_mobilenet_v1_coco model from the model zoo or any other model of your choice from TensorFlow 1 Detection Model Zoo. Download Dataset & utils. Download labelImg tool for labeling images. before extraction, you should have the following compressed files - STEP-2 Extract all the above zip files into a tfod folder and remove the compressed files- Now you should have the following folders - STEP-3 Creating virtual env using conda- Commands for specific python version conda create -n your_env_name python=3.7 for latest python version conda activate your_env_name STEP-4 Install the following packages in your new environment- for GPU pip install pillow lxml Cython contextlib2 jupyter matplotlib pandas opencv-python tensorflow-gpu==1.15.0 for CPU only pip install pillow lxml Cython contextlib2 jupyter matplotlib pandas opencv-python tensorflow==1.15.0 STEP-5 Install protobuf using conda package manager- conda install -c anaconda protobuf STEP-6 For protobuff to .py conversion download from a tool from here- For windows -> download source for other versions and OS - click here Open command prompt and cd to research folder. Now in the research folder run the following command- For Linux or Mac protoc object_detection/protos/*.proto --python_out=. For Windows protoc object_detection/protos/*.proto --python_out=. STEP-7 Paste all content present in utils into research folder- Following are the files and folder present in the utils folder- STEP-8 Paste ssd_mobilenet_v1_coco or any other model downloaded from model zoo into research folder- Now cd to the research folder and run the following python file- python xml_to_csv.py STEP-9 Run the following to generate train and test records- from the research folder- python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record STEP-10 Copy from research/object_detection/samples/config/ YOURMODEL.config file into research/training - Note The following config file shown here is with respect to ssd_mobilenet_v1_coco . So if you have downloaded it for any other model apart from SSD you'll see config file with YOUR_MODEL_NAME as shown below- model { YOUR_MODEL_NAME { num_classes: 6 box_coder { faster_rcnn_box_coder { Hence always verify YOUR_MODEL_NAME before using the config file. STEP-11 Update num_classes, fine_tune_checkpoint ,and num_steps plus update input_path and label_map_path for both train_input_reader and eval_input_reader - Info Changes to be made in the config file are highlighted in yellow color. You must update the value of those keys in the config file. Click here to see the full config file 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 # SSDLi te wi t h Mobile net v 1 co nf igura t io n f or MSCOCO Da taset . # Users should co nf igure t he f i ne _ tune _checkpoi nt f ield i n t he tra i n co nf ig as # well as t he label_map_pa t h a n d i n pu t _pa t h f ields i n t he tra i n _i n pu t _reader a n d # eval_i n pu t _reader. Search f or \"PATH_TO_BE_CONFIGURED\" t o f i n d t he f ields t ha t # should be co nf igured. model { ssd { nu m_classes : 6 box_coder { faster _rc nn _box_coder { y_scale : 10.0 x_scale : 10.0 heigh t _scale : 5.0 wid t h_scale : 5.0 } } ma t cher { argmax_ma t cher { ma t ched_ t hreshold : 0.5 u n ma t ched_ t hreshold : 0.5 ig n ore_ t hresholds : false ne ga t ives_lower_ t ha n _u n ma t ched : true f orce_ma t ch_ f or_each_row : true } } similari t y_calcula t or { iou_similari t y { } } a n chor_ge nerat or { ssd_a n chor_ge nerat or { nu m_layers : 6 mi n _scale : 0.2 max_scale : 0.95 aspec t _ra t ios : 1.0 aspec t _ra t ios : 2.0 aspec t _ra t ios : 0.5 aspec t _ra t ios : 3.0 aspec t _ra t ios : 0.3333 } } image_resizer { f ixed_shape_resizer { heigh t : 300 wid t h : 300 } } box_predic t or { co n volu t io nal _box_predic t or { mi n _dep t h : 0 max_dep t h : 0 nu m_layers_be f ore_predic t or : 0 use_dropou t : false dropou t _keep_probabili t y : 0.8 ker nel _size : 3 use_dep t hwise : true box_code_size : 4 apply_sigmoid_ t o_scores : false co n v_hyperparams { ac t iva t io n : RELU_ 6 , regularizer { l 2 _regularizer { weigh t : 0.00004 } } i n i t ializer { trun ca te d_ n ormal_i n i t ializer { s t ddev : 0.03 mea n : 0.0 } } ba t ch_ n orm { tra i n : true , scale : true , ce nter : true , decay : 0.9997 , epsilo n : 0.001 , } } } } feature _ex tra c t or { t ype : 'ssd_mobile net _v 1 ' mi n _dep t h : 16 dep t h_mul t iplier : 1.0 use_dep t hwise : true co n v_hyperparams { ac t iva t io n : RELU_ 6 , regularizer { l 2 _regularizer { weigh t : 0.00004 } } i n i t ializer { trun ca te d_ n ormal_i n i t ializer { s t ddev : 0.03 mea n : 0.0 } } ba t ch_ n orm { tra i n : true , scale : true , ce nter : true , decay : 0.9997 , epsilo n : 0.001 , } } } loss { classi f ica t io n _loss { weigh te d_sigmoid { } } localiza t io n _loss { weigh te d_smoo t h_l 1 { } } hard_example_mi ner { nu m_hard_examples : 3000 iou_ t hreshold : 0.99 loss_ t ype : CLASSIFICATION max_ ne ga t ives_per_posi t ive : 3 mi n _ ne ga t ives_per_image : 0 } classi f ica t io n _weigh t : 1.0 localiza t io n _weigh t : 1.0 } n ormalize_loss_by_ nu m_ma t ches : true pos t _processi n g { ba t ch_ n o n _max_suppressio n { score_ t hreshold : 1e-8 iou_ t hreshold : 0.6 max_de te c t io ns _per_class : 100 max_ t o tal _de te c t io ns : 100 } score_co n ver ter : SIGMOID } } } tra i n _co nf ig : { ba t ch_size : 24 op t imizer { rms_prop_op t imizer : { lear n i n g_ra te : { expo nent ial_decay_lear n i n g_ra te { i n i t ial_lear n i n g_ra te : 0.004 decay_s te ps : 800720 decay_ fa c t or : 0.95 } } mome ntu m_op t imizer_value : 0.9 decay : 0.9 epsilo n : 1.0 } } f i ne _ tune _checkpoi nt : \"ssd_mobilenet_v1_coco_2018_01_28/model.ckpt\" fr om_de te c t io n _checkpoi nt : true # No te : The below li ne limi ts t he tra i n i n g process t o 200 K s te ps , which we # empirically f ou n d t o be su ff icie nt e n ough t o tra i n t he pe ts da taset . This # e ffe c t ively bypasses t he lear n i n g ra te schedule ( t he lear n i n g ra te will # ne ver decay). Remove t he below li ne t o tra i n i n de f i n i tel y. nu m_s te ps : 20000 da ta _augme ntat io n _op t io ns { ra n dom_horizo ntal _ fl ip { } } da ta _augme ntat io n _op t io ns { ssd_ra n dom_crop { } } } tra i n _i n pu t _reader : { tf _record_i n pu t _reader { i n pu t _pa t h : \"train.record\" } label_map_pa t h : \"training/labelmap.pbtxt\" } eval_co nf ig : { nu m_examples : 8000 # No te : The below li ne limi ts t he evalua t io n process t o 10 evalua t io ns . # Remove t he below li ne t o evalua te i n de f i n i tel y. max_evals : 10 } eval_i n pu t _reader : { tf _record_i n pu t _reader { i n pu t _pa t h : \"test.record\" } label_map_pa t h : \"training/labelmap.pbtxt\" shu ffle : false nu m_readers : 1 } STEP-12 From research/object_detection/legacy/ copy train.py to research folder legacy folder contains train.py as shown below - STEP-13 Copy deployment and nets folder from research/slim into the research folder- slim folder contains the following folders - STEP-14 NOW Run the following command from the research folder. This will start the training in your local system - Note copy the command and replace YOUR_MODEL.config with your own model's name for example ssd_mobilenet_v1_coco.config and then run it in cmd prompt or terminal. And make sure you are in research folder . python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/YOUR_MODEL.config Warning Always run all the commands in the research folder.","title":"Configuration steps for TensorFlow object detection-"},{"location":"#configuration-steps-for-tensorflow-object-detection-","text":"","title":"Configuration steps for TensorFlow object detection-"},{"location":"#step-1-download-the-following-content-","text":"Download v1.13.0 model. Download the ssd_mobilenet_v1_coco model from the model zoo or any other model of your choice from TensorFlow 1 Detection Model Zoo. Download Dataset & utils. Download labelImg tool for labeling images. before extraction, you should have the following compressed files -","title":"STEP-1 Download the following content-"},{"location":"#step-2-extract-all-the-above-zip-files-into-a-tfod-folder-and-remove-the-compressed-files-","text":"Now you should have the following folders -","title":"STEP-2 Extract all the above zip files into a tfod folder and remove the compressed files-"},{"location":"#step-3-creating-virtual-env-using-conda-","text":"Commands for specific python version conda create -n your_env_name python=3.7 for latest python version conda activate your_env_name","title":"STEP-3 Creating virtual env using\u00a0conda-"},{"location":"#step-4-install-the-following-packages-in-your-new-environment-","text":"","title":"STEP-4 Install the following packages in your new environment-"},{"location":"#for-gpu","text":"pip install pillow lxml Cython contextlib2 jupyter matplotlib pandas opencv-python tensorflow-gpu==1.15.0","title":"for GPU"},{"location":"#for-cpu-only","text":"pip install pillow lxml Cython contextlib2 jupyter matplotlib pandas opencv-python tensorflow==1.15.0","title":"for CPU only"},{"location":"#step-5-install-protobuf-using-conda-package-manager-","text":"conda install -c anaconda protobuf","title":"STEP-5 Install protobuf using conda package manager-"},{"location":"#step-6-for-protobuff-to-py-conversion-download-from-a-tool-from-here-","text":"For windows -> download source for other versions and OS - click here Open command prompt and cd to research folder. Now in the research folder run the following command-","title":"STEP-6 For protobuff to\u00a0.py conversion download from a tool from here-"},{"location":"#for-linux-or-mac","text":"protoc object_detection/protos/*.proto --python_out=.","title":"For Linux or Mac"},{"location":"#for-windows","text":"protoc object_detection/protos/*.proto --python_out=.","title":"For Windows"},{"location":"#step-7-paste-all-content-present-in-utils-into-research-folder-","text":"Following are the files and folder present in the utils folder-","title":"STEP-7 Paste all content present in utils into research folder-"},{"location":"#step-8-paste-ssd_mobilenet_v1_coco-or-any-other-model-downloaded-from-model-zoo-into-research-folder-","text":"Now cd to the research folder and run the following python file- python xml_to_csv.py","title":"STEP-8 Paste ssd_mobilenet_v1_coco or any other model downloaded from model zoo into research folder-"},{"location":"#step-9-run-the-following-to-generate-train-and-test-records-","text":"from the research folder- python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record","title":"STEP-9 Run the following to generate train and test records-"},{"location":"#step-10-copy-from-researchobject_detectionsamplesconfig-yourmodelconfig-file-into-researchtraining-","text":"Note The following config file shown here is with respect to ssd_mobilenet_v1_coco . So if you have downloaded it for any other model apart from SSD you'll see config file with YOUR_MODEL_NAME as shown below- model { YOUR_MODEL_NAME { num_classes: 6 box_coder { faster_rcnn_box_coder { Hence always verify YOUR_MODEL_NAME before using the config file.","title":"STEP-10 Copy from research/object_detection/samples/config/ YOURMODEL.config file into research/training-"},{"location":"#step-11-update-num_classes-fine_tune_checkpoint-and-num_steps-plus-update-input_path-and-label_map_path-for-both-train_input_reader-and-eval_input_reader-","text":"Info Changes to be made in the config file are highlighted in yellow color. You must update the value of those keys in the config file. Click here to see the full config file 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 # SSDLi te wi t h Mobile net v 1 co nf igura t io n f or MSCOCO Da taset . # Users should co nf igure t he f i ne _ tune _checkpoi nt f ield i n t he tra i n co nf ig as # well as t he label_map_pa t h a n d i n pu t _pa t h f ields i n t he tra i n _i n pu t _reader a n d # eval_i n pu t _reader. Search f or \"PATH_TO_BE_CONFIGURED\" t o f i n d t he f ields t ha t # should be co nf igured. model { ssd { nu m_classes : 6 box_coder { faster _rc nn _box_coder { y_scale : 10.0 x_scale : 10.0 heigh t _scale : 5.0 wid t h_scale : 5.0 } } ma t cher { argmax_ma t cher { ma t ched_ t hreshold : 0.5 u n ma t ched_ t hreshold : 0.5 ig n ore_ t hresholds : false ne ga t ives_lower_ t ha n _u n ma t ched : true f orce_ma t ch_ f or_each_row : true } } similari t y_calcula t or { iou_similari t y { } } a n chor_ge nerat or { ssd_a n chor_ge nerat or { nu m_layers : 6 mi n _scale : 0.2 max_scale : 0.95 aspec t _ra t ios : 1.0 aspec t _ra t ios : 2.0 aspec t _ra t ios : 0.5 aspec t _ra t ios : 3.0 aspec t _ra t ios : 0.3333 } } image_resizer { f ixed_shape_resizer { heigh t : 300 wid t h : 300 } } box_predic t or { co n volu t io nal _box_predic t or { mi n _dep t h : 0 max_dep t h : 0 nu m_layers_be f ore_predic t or : 0 use_dropou t : false dropou t _keep_probabili t y : 0.8 ker nel _size : 3 use_dep t hwise : true box_code_size : 4 apply_sigmoid_ t o_scores : false co n v_hyperparams { ac t iva t io n : RELU_ 6 , regularizer { l 2 _regularizer { weigh t : 0.00004 } } i n i t ializer { trun ca te d_ n ormal_i n i t ializer { s t ddev : 0.03 mea n : 0.0 } } ba t ch_ n orm { tra i n : true , scale : true , ce nter : true , decay : 0.9997 , epsilo n : 0.001 , } } } } feature _ex tra c t or { t ype : 'ssd_mobile net _v 1 ' mi n _dep t h : 16 dep t h_mul t iplier : 1.0 use_dep t hwise : true co n v_hyperparams { ac t iva t io n : RELU_ 6 , regularizer { l 2 _regularizer { weigh t : 0.00004 } } i n i t ializer { trun ca te d_ n ormal_i n i t ializer { s t ddev : 0.03 mea n : 0.0 } } ba t ch_ n orm { tra i n : true , scale : true , ce nter : true , decay : 0.9997 , epsilo n : 0.001 , } } } loss { classi f ica t io n _loss { weigh te d_sigmoid { } } localiza t io n _loss { weigh te d_smoo t h_l 1 { } } hard_example_mi ner { nu m_hard_examples : 3000 iou_ t hreshold : 0.99 loss_ t ype : CLASSIFICATION max_ ne ga t ives_per_posi t ive : 3 mi n _ ne ga t ives_per_image : 0 } classi f ica t io n _weigh t : 1.0 localiza t io n _weigh t : 1.0 } n ormalize_loss_by_ nu m_ma t ches : true pos t _processi n g { ba t ch_ n o n _max_suppressio n { score_ t hreshold : 1e-8 iou_ t hreshold : 0.6 max_de te c t io ns _per_class : 100 max_ t o tal _de te c t io ns : 100 } score_co n ver ter : SIGMOID } } } tra i n _co nf ig : { ba t ch_size : 24 op t imizer { rms_prop_op t imizer : { lear n i n g_ra te : { expo nent ial_decay_lear n i n g_ra te { i n i t ial_lear n i n g_ra te : 0.004 decay_s te ps : 800720 decay_ fa c t or : 0.95 } } mome ntu m_op t imizer_value : 0.9 decay : 0.9 epsilo n : 1.0 } } f i ne _ tune _checkpoi nt : \"ssd_mobilenet_v1_coco_2018_01_28/model.ckpt\" fr om_de te c t io n _checkpoi nt : true # No te : The below li ne limi ts t he tra i n i n g process t o 200 K s te ps , which we # empirically f ou n d t o be su ff icie nt e n ough t o tra i n t he pe ts da taset . This # e ffe c t ively bypasses t he lear n i n g ra te schedule ( t he lear n i n g ra te will # ne ver decay). Remove t he below li ne t o tra i n i n de f i n i tel y. nu m_s te ps : 20000 da ta _augme ntat io n _op t io ns { ra n dom_horizo ntal _ fl ip { } } da ta _augme ntat io n _op t io ns { ssd_ra n dom_crop { } } } tra i n _i n pu t _reader : { tf _record_i n pu t _reader { i n pu t _pa t h : \"train.record\" } label_map_pa t h : \"training/labelmap.pbtxt\" } eval_co nf ig : { nu m_examples : 8000 # No te : The below li ne limi ts t he evalua t io n process t o 10 evalua t io ns . # Remove t he below li ne t o evalua te i n de f i n i tel y. max_evals : 10 } eval_i n pu t _reader : { tf _record_i n pu t _reader { i n pu t _pa t h : \"test.record\" } label_map_pa t h : \"training/labelmap.pbtxt\" shu ffle : false nu m_readers : 1 }","title":"STEP-11 Update num_classes, fine_tune_checkpoint ,and num_steps plus update input_path and label_map_path for both train_input_reader and eval_input_reader-"},{"location":"#step-12-from-researchobject_detectionlegacy-copy-trainpy-to-research-folder","text":"legacy folder contains train.py as shown below -","title":"STEP-12 From research/object_detection/legacy/ copy train.py to research folder"},{"location":"#step-13-copy-deployment-and-nets-folder-from-researchslim-into-the-research-folder-","text":"slim folder contains the following folders -","title":"STEP-13 Copy deployment and nets folder from research/slim into the research\u00a0folder-"},{"location":"#step-14-now-run-the-following-command-from-the-research-folder-this-will-start-the-training-in-your-local-system-","text":"Note copy the command and replace YOUR_MODEL.config with your own model's name for example ssd_mobilenet_v1_coco.config and then run it in cmd prompt or terminal. And make sure you are in research folder . python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/YOUR_MODEL.config Warning Always run all the commands in the research folder.","title":"STEP-14 NOW Run the following command from the research folder. This will start the training in your local\u00a0system-"},{"location":"p02/","text":"Google Colab setup for tfod Steps to start training in Google Colab for tfod- STEP 1. Do all the necessary steps shown on the previous page in your local system except the last step where training starts- Note I mean do everything before the following step- python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssdlite_mobilenet_v1_coco.config STEP 2.Move whole tfod folder to your google drive. verify that it should have atleast the below content- Note I'm using the ssd_mobilenet_v1_coco model that's I have ssd_mobilenet_v1_coco folder in the screenshot. You can upload your choice of the model there. Tip Since you have already done tfod set up in your local system and already copied utils and your model zoo folder (i.e ssd_mobilenet_v1_coco in my case). So if you want then you can only upload models-1.13.0 , folder instead of all of them. Here I have uploaded all of them just to replicate the exact same steps in local and Google Colab. STEP 3. Open a jupyter notebook in the root of your folder structure. I mean just inside the tfod folder. As you can see in the below screenshot you can see t01.ipynb . STEP 4. Mount the drive in Colab and initialize it with GPU. Refer the following video - STEP 5. In the first cell run the following command so that it selects TensorFlow 1 for the training- %tensorflow_version 1.x STEP 6. In the notebook import os. And set a path to the research directory in a Variable as per your google drive. import os RESEARCH_DIR = \"/content/drive/My Drive/PATH_TO_TFOD/tfod/models-1.13.0/research\" STEP 7. Run the following line to change the directory- os . chdir ( RESEARCH_DIR ) STEP 8. Run the following line to verify that you are in the research folder- os . getcwd () STEP 9. Now run the training command to start the training in Google Colab- Note Change the name of the config file as per your model name !python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssdlite_mobilenet_v1_coco.config STEP 10. Copy and paste following code in your browser console to prevent Google Colab from terminating- JS code 1 - function ClickConnect (){ console . log ( \"Working\" ); document . querySelector ( \"colab-toolbar-button\" ). click () } setInterval ( ClickConnect , 60000 ) Refer the video below for final setup - Screenshot of Google Colab code- Screenshot of begining of final training- \"How to prevent Google Colab from disconnecting ?\" | MEDIUM BLOG \u21a9","title":"Google Colab setup for\u00a0tfod"},{"location":"p02/#google-colab-setup-for-tfod","text":"Steps to start training in Google Colab for tfod-","title":"Google Colab setup for\u00a0tfod"},{"location":"p02/#step-1-do-all-the-necessary-steps-shown-on-the-previous-page-in-your-local-system-except-the-last-step-where-training-starts-","text":"Note I mean do everything before the following step- python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssdlite_mobilenet_v1_coco.config","title":"STEP 1. Do all the necessary steps shown on the previous page in your local system except the last step where training\u00a0starts-"},{"location":"p02/#step-2move-whole-tfod-folder-to-your-google-drive","text":"verify that it should have atleast the below content- Note I'm using the ssd_mobilenet_v1_coco model that's I have ssd_mobilenet_v1_coco folder in the screenshot. You can upload your choice of the model there. Tip Since you have already done tfod set up in your local system and already copied utils and your model zoo folder (i.e ssd_mobilenet_v1_coco in my case). So if you want then you can only upload models-1.13.0 , folder instead of all of them. Here I have uploaded all of them just to replicate the exact same steps in local and Google Colab.","title":"STEP 2.Move whole tfod folder to your google drive."},{"location":"p02/#step-3-open-a-jupyter-notebook-in-the-root-of-your-folder-structure-i-mean-just-inside-the-tfod-folder","text":"As you can see in the below screenshot you can see t01.ipynb .","title":"STEP 3. Open a jupyter notebook in the root of your folder structure. I mean just inside the tfod folder."},{"location":"p02/#step-4-mount-the-drive-in-colab-and-initialize-it-with-gpu","text":"","title":"STEP 4. Mount the drive in Colab and initialize it with GPU."},{"location":"p02/#refer-the-following-video-","text":"","title":"Refer the following video -"},{"location":"p02/#step-5-in-the-first-cell-run-the-following-command-so-that-it-selects-tensorflow-1-for-the-training-","text":"%tensorflow_version 1.x","title":"STEP 5. In the first cell run the following command so that it selects TensorFlow 1 for the training-"},{"location":"p02/#step-6-in-the-notebook-import-os-and-set-a-path-to-the-research-directory-in-a-variable-as-per-your-google-drive","text":"import os RESEARCH_DIR = \"/content/drive/My Drive/PATH_TO_TFOD/tfod/models-1.13.0/research\"","title":"STEP 6. In the notebook import os. And set a path to the research directory in a Variable as per your google drive."},{"location":"p02/#step-7-run-the-following-line-to-change-the-directory-","text":"os . chdir ( RESEARCH_DIR )","title":"STEP 7. Run the following line to change the directory-"},{"location":"p02/#step-8-run-the-following-line-to-verify-that-you-are-in-the-research-folder-","text":"os . getcwd ()","title":"STEP 8. Run the following line to verify that you are in the research folder-"},{"location":"p02/#step-9-now-run-the-training-command-to-start-the-training-in-google-colab-","text":"Note Change the name of the config file as per your model name !python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssdlite_mobilenet_v1_coco.config","title":"STEP 9. Now run the training command to start the training in Google\u00a0Colab-"},{"location":"p02/#step-10-copy-and-paste-following-code-in-your-browser-console-to-prevent-google-colab-from-terminating-","text":"JS code 1 - function ClickConnect (){ console . log ( \"Working\" ); document . querySelector ( \"colab-toolbar-button\" ). click () } setInterval ( ClickConnect , 60000 ) Refer the video below for final setup -","title":"STEP 10. Copy and paste following code in your browser console to prevent  Google\u00a0Colab from terminating-"},{"location":"p02/#screenshot-of-google-colab-code-","text":"","title":"Screenshot of Google Colab\u00a0code-"},{"location":"p02/#screenshot-of-begining-of-final-training-","text":"\"How to prevent Google Colab from disconnecting ?\" | MEDIUM BLOG \u21a9","title":"Screenshot of begining of final training-"},{"location":"referencesAndFeedback/","text":"References iNeuron docs TensorFlow Object Detection API | tutorial TensorFlow Object Detection | GitHub \"How to prevent Google Colab from disconnecting ?\" | MEDIUM BLOG \"Getting Local with Google Colab\" | MEDIUM BLOG For any Feedback - Feedback Hi fellow Devs, I've tried my best to make this documentation as good as possible and also I've mentioned almost all the references that I've refered. Apart from that if you wish to give some constructive feedback then please mail me at - sunny.c17hawke@gmail.com Thanks and Regards, Sunny Bhaveen Chandra","title":"References"},{"location":"referencesAndFeedback/#references","text":"iNeuron docs TensorFlow Object Detection API | tutorial TensorFlow Object Detection | GitHub \"How to prevent Google Colab from disconnecting ?\" | MEDIUM BLOG \"Getting Local with Google Colab\" | MEDIUM BLOG","title":"References"},{"location":"referencesAndFeedback/#for-any-feedback-","text":"Feedback Hi fellow Devs, I've tried my best to make this documentation as good as possible and also I've mentioned almost all the references that I've refered. Apart from that if you wish to give some constructive feedback then please mail me at - sunny.c17hawke@gmail.com Thanks and Regards, Sunny Bhaveen Chandra","title":"For any Feedback -"}]}